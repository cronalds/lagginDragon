## Core Idea

You want to:

- Represent facts as **sets of discrete values** (e.g., `{no, maybe, yes}`, `{girlRaped, girlAllegedlyRaped, girlNotRaped}`).
- Encode **rules** (Horn-clause style, `premises â‡’ consequence`).
- Use **short-circuit evaluation** with logical gates to prune impossible worlds.
- Derive **new premises** recursively by feeding consequences back into the KB.

This is very close to **logic programming (Prolog)** but extended to handle:

- **Non-binary states** (more than just true/false).
- **Defeasible reasoning** (alleged vs. confirmed states).
- **Propagation** of uncertainty (`maybe`) rather than pruning it outright.

0. [[0. Core Concepts]]
1. [[00.. Implementation Path]]
2. [[1. Knowledge Representation]]
	- [[1.1 Provenance and Explainability]]
3. [[2. Logical Evaluation]]
	- [[2.1 Evaluation and Short-Circuiting Facade]]
	- [[2.2 Prioritization and Defeasible Reasoning]]
	- [[2.3 Command Pattern]]
	- [[2.4 Short-Circuiting Rules]]
	- [[2.5 Rule Builder]]
4. [[3. Inference Process]]
	- [[3.1 Inference Loop (High Level Pipeline)]]
	- [[3.2 Parallel Worlds and Branching on Unknowns]]
5. [[4. Handling Contradictions]]
6. [[5. Core Data Model Concepts]]
	- [[5.1 Data Model Sketches]]
7. [[6. Conflict Handling Strategies]]
	- [[6.1 Conflict and Prioritization (Practical Rules)]]
8. [[7. Tracing, Logging, and Kanban Templating]]
	- [[7.1 Traceability and Replay Guarantees]]
	- [[7.2 Testing and Validation Plan]]
9. [[8.  Testing, Validation, and Safety]] 

[[Figure Out Properly Later]]

### Suggested Architecture

- **Fact Base**: Stores current facts + provenance (who said it, when, certainty).
- **Rule Engine**: Evaluates Horn clauses and consequences.
- **Contradiction Resolver**: Detects conflicts and applies resolution rules.
- **Inference Chain**: Stores history (important for traceability in court).
- **Worlds**: Active vs. pruned worlds for scenario management.